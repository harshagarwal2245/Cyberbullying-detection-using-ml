{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3344d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import random as rnd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import string\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293def5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "\n",
    "df=pd.read_json(\"D:\\B.E\\sem7\\Project work stage1\\cyberbullying\\Dataset for Detection of Cyber-Trolls.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a060bd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0                             Get fucking real dude.   \n",
       "1   She is as dirty as they come  and that crook ...   \n",
       "2   why did you fuck it up. I could do it all day...   \n",
       "3   Dude they dont finish enclosing the fucking s...   \n",
       "4   WTF are you talking about Men? No men thats n...   \n",
       "\n",
       "                      annotation  label  \n",
       "0  {'notes': '', 'label': ['1']}      1  \n",
       "1  {'notes': '', 'label': ['1']}      1  \n",
       "2  {'notes': '', 'label': ['1']}      1  \n",
       "3  {'notes': '', 'label': ['1']}      1  \n",
       "4  {'notes': '', 'label': ['1']}      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"] = df.annotation.apply(lambda x: x.get('label'))\n",
    "df[\"label\"] = df.label.apply(lambda x: x[0])\n",
    "df['label']=df['label'].astype(int)\n",
    "df.drop(['extras'],inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0f7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[\"content\"]\n",
    "y=df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad52576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Python\n",
    "# Open the file for writing\n",
    "F = open('list.txt', 'w')\n",
    "\n",
    "# The reason why we used a list comprehension \n",
    "# is that we wanted to convert the numbers to \n",
    "# strings so that they can be written to disk\n",
    "F.writelines([str(x) + \"\\n\" for x in x])\n",
    "\n",
    "# Close the file\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfd5f201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 13400\n",
      "X_test: 6600\n",
      "y_train 13400\n",
      "y_test 6600\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "print(\"X_train:\",len(x_train))\n",
    "print(\"X_test:\",len(x_test))\n",
    "print(\"y_train\",len(y_train))\n",
    "print(\"y_test\",len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992fee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 14318\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(x_train,y_train)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0406e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " HAHAHHAHAAHHAHAHA LULZ   @Mod_Alex  your STILL a cunt!!!!! hahahahahahahah lulz lulz lulz lulz lulz\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['hahahhahaahhahaha', 'lulz', 'still', 'cunt', 'hahahahahahahah', 'lulz', 'lulz', 'lulz', 'lulz', 'lulz']\n"
     ]
    }
   ],
   "source": [
    "print('This is an example of a positive tweet: \\n', x_train[7070])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(x_train[7070]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f3c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a395e09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.043e+03, 1.854e+03]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(x_train[17244],freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9c0878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.0\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(x_train), 3))\n",
    "z=0\n",
    "for i in x_train:\n",
    "    X[z, :]= extract_features(i, freqs)\n",
    "    z+=1\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = y_train\n",
    "print(X[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47aaadfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7070     1\n",
      "13010    0\n",
      "6688     1\n",
      "9976     0\n",
      "5175     1\n",
      "        ..\n",
      "11284    0\n",
      "11964    0\n",
      "5390     1\n",
      "860      1\n",
      "15795    0\n",
      "Name: label, Length: 13400, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "636ecba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(C=89,random_state=0)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=800, random_state=0,max_features=6)\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=0,)\n",
    "knn_clf=KNeighborsClassifier(metric=\"euclidean\",n_neighbors=7)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('knn', knn_clf),('svc',svm_clf)],\n",
    "    voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c95c6a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=89, random_state=0)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(metric='euclidean',\n",
       "                                                   n_neighbors=7)),\n",
       "                             ('svc', SVC(gamma='auto', random_state=0))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e1a55ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=89, random_state=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7f07710e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e26a3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t= np.zeros((len(x_test), 3))\n",
    "z=0\n",
    "for i in x_test:\n",
    "    X_t[z, :]= extract_features(i, freqs)\n",
    "    z+=1\n",
    "Y_t=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "67c64fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6593939393939394\n",
      "SVC 0.9346969696969697\n",
      "KNeighborsClassifier 0.7206060606060606\n",
      "VotingClassifier 0.8254545454545454\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf,svm_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X, Y)\n",
    "    y_pred = clf.predict(X_t)\n",
    "    print(clf.__class__.__name__, accuracy_score(Y_t, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "825bfd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3619,  400],\n",
       "       [ 752, 1829]], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_t,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6b99bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      4019\n",
      "           1       0.82      0.71      0.76      2581\n",
      "\n",
      "    accuracy                           0.83      6600\n",
      "   macro avg       0.82      0.80      0.81      6600\n",
      "weighted avg       0.83      0.83      0.82      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_t,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
